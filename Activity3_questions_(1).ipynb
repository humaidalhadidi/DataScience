{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/humaidalhadidi/DataScience/blob/main/Activity3_questions_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color = blue size = 6> **Activity #3 (5 marks)**"
      ],
      "metadata": {
        "id": "9Hr2lLFuZjja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<font color = green size = 5> **Activity: Air Quality Analysis in NYC**"
      ],
      "metadata": {
        "id": "bEtXiTwI-yIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective:\n",
        "- **Objective:**  \n",
        "The goal of this assignment is to analyze air quality data collected from low-cost sensors mounted on moving vehicles in New York City. Using the concepts learned in the chapters on Sampling and Empirical Distributions , Testing Hypotheses , and Estimation , you will perform statistical analysis to estimate pollution levels, test hypotheses about differences in pollution across neighborhoods, and construct confidence intervals for key parameters.\n",
        "\n",
        "You are provided with a `Datascience` `Table` named `joined_table`, which contains air quality readings (`pm10`) and their corresponding administrative divisions (neighborhoods) in NYC. The table has been preprocessed and joined with neighborhood boundaries using geospatial operations. Your task is to perform all subsequent tasks using the `Datascience` Table abstraction as taught in class."
      ],
      "metadata": {
        "id": "6i3-zemYyZAu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "given a csv file containing longitude, latitude , and pm10  columns [Air Quality data](https://raw.githubusercontent.com/IsamAljawarneh/datasets/master/data/NYC_PM.csv) representing readings of low cost air quality sensor mounted on moving vehicles, in addition to a geojson file containing polygons representing administrative divisions of NYC city known as neighbourhoods [nyc_polygon.geojson](https://raw.githubusercontent.com/IsamAljawarneh/datasets/master/data/nyc_polygon.geojson).\n",
        "# Dataset Description\n",
        "- Air Quality Sensor Readings (NYC_PM.csv) :\n",
        "Attributes: SensorID, time, temperature, humidity, pm25,\n",
        "Focus attributes: temperature, humidity, pm1,pm25,pm10,\n",
        "- City Polygons (nyc_polygon.geojson) :\n",
        "Contains polygons representing neighborhoods or boroughs in NYC.\n",
        "Used for spatially joining geographic information with air quality data."
      ],
      "metadata": {
        "id": "MnPCkUN9-lzy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **part - A** preprocessing [0 marks]\n",
        "\n",
        "do all tasks and the subtasks!"
      ],
      "metadata": {
        "id": "_kuVRsJkAh9n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Onboarding Code Provided\n",
        "- The following code will be provided in an onboarding Jupyter Notebook to help students get started:\n",
        "\n"
      ],
      "metadata": {
        "id": "cXRH1R-SzPAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''from google.colab import drive\n",
        "drive.mount('/content/drive')'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R4ArO-FctZIu",
        "outputId": "9a81603c-6c0f-4f9c-aef6-5cbeb860de2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"from google.colab import drive\\ndrive.mount('/content/drive')\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import necessary libraries"
      ],
      "metadata": {
        "id": "9o9eM8IICM-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "DIyY1q36ta3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datascience import *\n",
        "%matplotlib inline\n",
        "#path_data = '../../../assets/data/'\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8ipkPRynmWGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Read the CSV file containing PM sensor readings\n",
        " & Read the GeoJSON file containing neighborhood boundaries into a GeoDataFrame"
      ],
      "metadata": {
        "id": "11VvbD-a6ur8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 1: Read the CSV file containing PM10 sensor readings\n",
        "pm10_data = pd.read_csv('https://raw.githubusercontent.com/IsamAljawarneh/datasets/master/data/NYC_PM.csv',index_col=False)\n",
        "\n",
        "# Step 2: Read the GeoJSON file containing neighborhood boundaries into a GeoDataFrame\n",
        "nyc_neighborhoods = gpd.read_file('https://raw.githubusercontent.com/IsamAljawarneh/datasets/master/data/nyc_polygon.geojson')\n"
      ],
      "metadata": {
        "id": "CYk7KfJqueQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pm10_data.dtypes"
      ],
      "metadata": {
        "id": "VAMLIDAKu289"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. convert the csv into a geodataframe and join it (sjoin) with the geojson, assign a coordinate reference system (CRS) the csv geodataframe which is identical to that of the geojson file, then perform the join, the result is a geodataframe, convert it to dataframe, and select pm10, neighborhood columns in a new dataframe"
      ],
      "metadata": {
        "id": "tKKuGLIl682s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pm10_gdf = gpd.GeoDataFrame(pm10_data, geometry=gpd.points_from_xy(pm10_data.longitude, pm10_data.latitude))\n",
        "merged_data = gpd.sjoin(pm10_gdf, nyc_neighborhoods, how='inner', predicate='within')"
      ],
      "metadata": {
        "id": "LDdZ3JM9vABk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "256026e9-7089-4322-8577-9a4f4d57642b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-d43866676e2a>:2: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
            "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
            "\n",
            "Left CRS: None\n",
            "Right CRS: EPSG:4326\n",
            "\n",
            "  merged_data = gpd.sjoin(pm10_gdf, nyc_neighborhoods, how='inner', predicate='within')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merged_data.dtypes"
      ],
      "metadata": {
        "id": "4YTL56jpvPDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_data = merged_data[['pm10','neighborhood']]"
      ],
      "metadata": {
        "id": "1XPU0kp4hwnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_data.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3gx_my1iAoi",
        "outputId": "0ceb7686-5f4b-47af-e93a-646e5dd0a2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118495"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#merged_data.rename(columns={'neighborhood': 'neighborhood1'}, inplace=True)"
      ],
      "metadata": {
        "id": "P4M9bOYqy09e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(pollution_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "a8C-waCXk8JE",
        "outputId": "45a8d50a-97d0-42a0-c7d8-0cf20c0e2be1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. you need to convert</h1></section> from dataframe to Datascience Table. Use the following format: ```Table.from_df(df, keep_index=False)``` read more here\n",
        "[create DS Table from DF](https://www.data8.org/datascience/_autosummary/datascience.tables.Table.from_df.html)\n",
        "\n",
        "**N.B.** <font color='red'>NOW, perform all tasks using the table abstraction as we have learned in the class!</font>"
      ],
      "metadata": {
        "id": "ajH-jZyp8neJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following is the opposite:\n",
        "\n",
        "[Table.to_df](https://www.data8.org/datascience/_autosummary/datascience.tables.Table.to_df.html)"
      ],
      "metadata": {
        "id": "ansU7tkQ9cj5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "what is the maximum pm10 value"
      ],
      "metadata": {
        "id": "2zHvKSpo7nX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_data['pm10'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Ikgdphzdha",
        "outputId": "80eccfdd-5a77-48a7-83db-d009bcabf069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87341.71"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "what is the maximum pm10 value"
      ],
      "metadata": {
        "id": "RgKB2UJo7rWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pollution_data['pm10'].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqANkwbXzmF5",
        "outputId": "87a1032c-eaf5-45a1-a46c-535c0eaaff49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joined_table = Table().from_df(pollution_data)"
      ],
      "metadata": {
        "id": "zsjLIScVmM9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "show the first few rows of the table?"
      ],
      "metadata": {
        "id": "KsUXysj_B1T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_table.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "lhgoak8vzEfS",
        "outputId": "9073dd57-f354-484e-a375-be257b93b53b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "    <thead>\n",
              "        <tr>\n",
              "            <th>pm10</th> <th>neighborhood</th>\n",
              "        </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "        <tr>\n",
              "            <td>11.35</td> <td>Bronx Park  </td>\n",
              "        </tr>\n",
              "        <tr>\n",
              "            <td>1.18 </td> <td>Bronx Park  </td>\n",
              "        </tr>\n",
              "    </tbody>\n",
              "</table>\n",
              "<p>... (118493 rows omitted)</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print minimum and maximum pm10 values?"
      ],
      "metadata": {
        "id": "zgAZOxbYB56N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pm10 = joined_table.column('pm10')\n",
        "min(pm10), max(pm10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ncrqo0y8l5",
        "outputId": "e02c5cfe-c3ca-4579-ea89-a334dc7959e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 87341.710000000006)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instructions for Students\n",
        "-You task is to analyze NYC hyperlocal air quality data using the provided dataset. Complete the following tasks in your Jupyter Notebook.total of 5 marks . Use the Table abstraction."
      ],
      "metadata": {
        "id": "kkbu-cal0QRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tasks"
      ],
      "metadata": {
        "id": "lNeAe-ZH0eL2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue size  = 5>**Task 1: Sampling and Empirical Distribution (1 Mark)**\n",
        "\n",
        "**Task Description:**\n",
        "\n",
        "- Randomly sample 10% of the rows from the joined_table without replacement.\n",
        "- Compute the mean pm10 value for this sample.\n",
        "- Create an empirical histogram of the pm10 values from the sampled data using 10 bins.\n",
        "- Comment on the shape of the histogram and compare it to the distribution of the full dataset."
      ],
      "metadata": {
        "id": "lTICc0fUdXNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color = red size= 5> attention</font>\n",
        "\n",
        "remove pm10 values that are unreasonably high (above 300 µg/m³)"
      ],
      "metadata": {
        "id": "H9u190hzeLnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joined_table = joined_table.where('pm10', are.below(300))"
      ],
      "metadata": {
        "id": "iXqSs3EDd7v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(joined_table)"
      ],
      "metadata": {
        "id": "XBQxvwlie-pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joined_table.num_rows"
      ],
      "metadata": {
        "id": "kLHMmWdHe6rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue size  = 5> **Task 2: Estimation and Confidence Intervals (1 Mark)**\n"
      ],
      "metadata": {
        "id": "CuJ4xIHXeZXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task Description:**\n",
        "- Use the bootstrap method to estimate the median pm10 value for the entire dataset.\n",
        "- Generate 5,000 bootstrap samples and compute the median for each sample.\n",
        "- Construct a 95% confidence interval for the population median using the 2.5th and 97.5th percentiles of the bootstrapped medians.\n",
        "- Visualize the results by drawing an `empirical histogram` of the bootstrapped medians and overlaying the confidence interval on the horizontal axis.\n",
        "- Report the confidence interval and interpret what it means in the context of air quality."
      ],
      "metadata": {
        "id": "w3fxSNsIq7RT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue size  = 5> **Task 3: Hypothesis Testing Using Confidence Intervals (1.5 Mark)**"
      ],
      "metadata": {
        "id": "9cs7K_Q3icPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task Description:**\n",
        "- Test the hypothesis about the average <font color = red size =5> `pm10` </font> level in the population using confidence intervals.\n",
        "  - Null Hypothesis (H0): The average pm10 level in the population is `20 μg/m³` .\n",
        "  - Alternative Hypothesis (Ha): The average pm10 level in the population is not `20 μg/m³` .\n",
        "- Use the confidence interval method to test this hypothesis:\n",
        "Construct a 95% confidence interval for the average `pm10` level in the population.\n",
        "  - If the confidence interval contains `20 μg/m³` , conclude that there is no significant difference from `20 μg/m³` (fail to reject H0).\n",
        "  - Otherwise, conclude that there is a significant difference (reject H0).\n",
        "- Interpret your results and explain whether the data supports the null hypothesis or the alternative hypothesis."
      ],
      "metadata": {
        "id": "Ukmexr5YivJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color = blue size  = 5> **Task 4: Percentiles and Extreme Values (1.5 Mark)**\n"
      ],
      "metadata": {
        "id": "A7cJxidKmB31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use the bootstrap method to simulate the mean `pm10` levels for each neighborhood. Generate 5,000 bootstrap samples for the top 3 neighborhoods with the highest mean pm10 levels.\n",
        "- Create an empirical histogram for each of these neighborhoods, showing the distribution of the bootstrapped means.\n",
        "- Overlay horizontal yellow lines to indicate the 95% confidence interval for the mean pm10 level in each neighborhood.\n"
      ],
      "metadata": {
        "id": "x1hoJVDEoIOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission Guidelines\n",
        "- Add a \"Open in Colab\" button at the top of your notebook using the following Markdown code:\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo-path/notebook.ipynb)\n",
        "\n",
        "- Upload your completed Jupyter Notebook to a GitHub repository.\n",
        "- Submit the link to your GitHub repository in the Blackboard LMS along with the Jupyter solution file.\n",
        "- <font color = red size = 6> ATTENTION!!! </font> Students are encouraged to work on groups, however the submission should be individual and each student should have her/his own unique final assignment solution, which is to be submitted in BB"
      ],
      "metadata": {
        "id": "kM16Gy602H1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grading Rubric\n",
        "based on the following criteria:\n",
        "\n",
        "- Correctness : The solution produces the expected output using the Table abstraction .\n",
        "- Clarity : Code is well-organized, readable, and includes comments explaining key steps.\n",
        "- Creativity : Visualizations and analyses are presented in an engaging and insightful manner."
      ],
      "metadata": {
        "id": "dY2-OB4A2huX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hints for Success\n",
        "- Use the Table abstraction methods like .select(), .where(), .group(), .apply(), and .sample() for data manipulation.\n",
        "- Refer to the slides and examples from book Chapters 10, 11, and 13, for guidance on Sampling and Empirical Distributions, Testing Hypotheses,  and Estimation.\n",
        "- Test your code frequently to ensure it runs without errors."
      ],
      "metadata": {
        "id": "0GlfWQnV2r9v"
      }
    }
  ]
}